---
title: 'How S3 Multipart Upload Works: From Bytes to Video'
summary: Understanding how large files are split and merged at the byte level
date: '2025-12-23'
tags: ['AWS']
draft: false
---

When uploading large files to S3, you'll use multipart upload. But to truly understand how "splitting a file for upload" actually works, and why split files can be merged back together perfectly, we need to understand the fundamental nature of files.

---

## 1. What is S3 Multipart Upload?

S3 Multipart Upload is a method of uploading large files by dividing them into smaller parts. AWS recommends using multipart upload for files over 100MB, and it's mandatory for files over 5GB.

Multipart upload proceeds in three stages. First, in the **Initiate** stage, you receive a unique Upload ID. Next, in the **Upload Parts** stage, the file is divided into parts (minimum 5MB, except for the last part) and each is uploaded separately. Each part receives a number from 1 to 10,000, and an ETag upon completion. Finally, in the **Complete** stage, the Complete Multipart Upload request combines the parts into a single object.

The benefits of this approach are clear. If the upload is interrupted due to network issues, only the failed parts need to be re-uploaded. Multiple parts can be uploaded in parallel, significantly improving upload speeds for large files. Files can even be uploaded in a streaming fashion without knowing the file size in advance.

One important consideration: if you start a multipart upload but don't complete or abort it, the incomplete parts remain stored in S3, incurring costs. It's recommended to configure a Lifecycle Policy to automatically delete incomplete multipart uploads older than 7 days.

<MultipartProcessDemo />

---

## 2. How Complete Multipart Upload Works

Complete Multipart Upload is an API call that tells S3 "I've uploaded all the parts, now combine them into a single object." The request body is in XML format, containing each part's number and ETag.

```xml
<CompleteMultipartUpload>
  <Part>
    <PartNumber>1</PartNumber>
    <ETag>"etag-value-1"</ETag>
  </Part>
  <Part>
    <PartNumber>2</PartNumber>
    <ETag>"etag-value-2"</ETag>
  </Part>
</CompleteMultipartUpload>
```

When S3 receives a Complete request, it verifies that each provided ETag matches the ETag of the actually uploaded part and confirms that part numbers are sequential and in correct order. It then concatenates parts in order to create the final object, calculates the final object's ETag, and cleans up the temporarily stored individual part data.

The ETag of objects created via multipart upload differs from regular uploads. A regular upload's ETag is the MD5 hash of the entire file, but multipart objects have the following format.

```
"d41d8cd98f00b204e9800998ecf8427e-3"
```

The `-3` at the end indicates the file was uploaded in 3 parts. The actual hash value is the MD5 of all part MD5s concatenated.

```
ETag = MD5(MD5(part1) + MD5(part2) + MD5(part3)) + "-" + partCount
```

Since S3 is a distributed storage system, each part may be stored in different physical locations. When a Complete request comes in, S3 doesn't physically copy the data—instead, it creates metadata stating "this object consists of parts 1, 2, 3." This approach allows even multi-GB files to complete in seconds.

<ETagVisualization />

---

## 3. The Essence of Files: A Sequence of Bytes

Here's the key question: Taking video files as an example, how can split parts of a video file be merged back into a single working file? To understand this, we need to know what a file actually is.

A file is ultimately **an ordered sequence of bytes**. Video files are no different.

```
video.mp4 = [byte0, byte1, byte2, ..., byteN]
```

For example, a 100MB video file contains 104,857,600 bytes, with actual content like `0x00 0x00 0x00 0x18 0x66 0x74 0x79 0x70 ...`. Dividing this into 3 parts gives Part 1 as bytes [0 ~ 34,952,533], Part 2 as bytes [34,952,534 ~ 69,905,066], and Part 3 as bytes [69,905,067 ~ 104,857,599].

MP4 files are structured with "boxes" or "atoms".

```
[ftyp box - file type]
[moov box - metadata: codec, resolution, duration, etc.]
  ├─ [mvhd - overall info]
  ├─ [trak - video track]
  └─ [trak - audio track]
[mdat box - actual video/audio data]
  ├─ Frame 1 data
  ├─ Frame 2 data
  └─ ...
```

However, **multipart upload completely ignores this structure**. It simply divides the byte array.

```python
file_bytes = read_entire_file()
part_size = len(file_bytes) // 3

part1 = file_bytes[0:part_size]
part2 = file_bytes[part_size:part_size*2]
part3 = file_bytes[part_size*2:]
```

Whether it cuts through the middle of a video file header or through a specific frame doesn't matter. It just mechanically divides bytes. Since Multipart Complete simply concatenates bytes in order, the exact same byte sequence as the original is restored.

You can verify this directly in the terminal.

```bash
# 1. Split test video file into 3 parts
split -n 3 video.mp4 part_

# 2. Merge back together
cat part_aa part_ab part_ac > reconstructed.mp4

# 3. Compare with original
md5sum video.mp4
md5sum reconstructed.mp4
# -> The two hash values are identical!
```

Video players will play `reconstructed.mp4` exactly like the original because it's byte-for-byte identical.

This simple approach works because **file formats are self-describing**. Video players start reading from the beginning, parse the header, determine "where everything is," then seek to those positions to read data. Whether uploaded via multipart or single upload, **as long as the bytes are in correct order**, everything works.

If the order is wrong, the MP4 header ends up in the middle so the player can't recognize the file type, and byte order is scrambled making playback impossible. That's why the Complete request **must include PartNumber**, and S3 concatenates exactly in that order.

<FileProvider>

<HexDumpExplorer />

---

## 4. How Bytes Become Video

Let's dive into an even more fundamental question. How do bytes become video?

Bytes are just numbers from 0 to 255. The same byte sequence becomes entirely different things depending on **how it's interpreted**. For example, the byte sequence `0x48 0x65 0x6C 0x6C 0x6F` becomes "Hello" when interpreted as ASCII text, 310,939,249,775 when interpreted as an integer, and Red=72, Green=101, Blue=108 when interpreted as RGB pixels.

Video is a grid of countless pixels (dots). A 1920x1080 resolution means 2,073,600 pixels, and each pixel has 3 RGB values (Red, Green, Blue). Stored in the simplest uncompressed form, one complete frame is 1920 × 1080 × 3 = 6,220,800 bytes, about 6MB. One second of 30fps video is 180MB. In practice, this is too large, so we compress it with codecs like H.264.

Compression works by removing spatial and temporal redundancy. If 1000 sky blue pixels are all similar, you just record "pixels (0,0) to (31,31): color 0x0080FF" once. If a car is at position (100, 200) in frame 1 and (105, 200) in frame 2, instead of storing both frames completely, you record "store frame 1 + frame 2 is 5 pixels right."

Video players do three things. First, in **Parsing**, they read the file and determine metadata (codec, resolution, frame positions, etc). Next, in **Decoding**, they decompress the compressed frame data with an H.264 decoder to restore the original pixel data. Finally, in **Rendering**, they send pixel data to the GPU to draw on screen.

Each pixel on a monitor is actually composed of red, green, and blue LEDs/LCDs. Byte value 255 means LED maximum brightness, 0 means LED off, 128 means half brightness. For RGB(255, 0, 0), only the red LED lights up at maximum brightness while the others stay off, appearing red to the eye.

<ByteInterpretationDemo />

---

## 5. Hierarchical Abstraction: From Electrons to Video

Summarizing the entire process, we get this layered structure.

```
Physical Level:
Electron flow → Voltage → LED brightness

Hardware Level:
0s and 1s → Bytes (8-bit groups)

File Format Level:
Byte sequence → Structured data
"These bytes are header, those bytes are pixel data"

Codec Level:
Compressed bytes → Original pixels restored

Application Level:
Pixel array → Video on screen
```

All digital media ultimately goes through three stages: **Encoding** (meaningful data → bytes), **Storage/Transmission** (bytes are just numbers), and **Decoding** (bytes → meaningful data). Video, music, documents, programs—all work on the same principle. The bytes are the same; only the **interpretation method** differs.

---

## 6. Back to Multipart Upload

Now it's clear why multipart upload works.

```
File = Ordered array of bytes
Multipart upload = Split array into chunks
Complete = Concatenate chunks in original order

video.mp4 [0...N]
    ↓ split
part1 [0...N/3]
part2 [N/3...2N/3]
part3 [2N/3...N]
    ↓ complete
video.mp4 [0...N] ✓
```

From a computer architecture perspective, whether it's memory, disk, or S3, it's ultimately an "addressable byte array," and files are just portions of that array. Multipart upload leverages this fundamental simplicity.

<MultipartVerifier />

</FileProvider>
